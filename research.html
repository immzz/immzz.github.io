<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Mingzhi Zeng's</title>
    
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Mingzhi Zeng</h1>
        
        <p class="view"><a href="projects.html">Projects<small>Some codings and ideas</small></a></p>
        <p class="view"><a href="research.html">Research<small>About Social Search</small></a></p>
        <p class="view"><a href="games.html">Early Games<small>Childish pieces of work</small></a></p>
        <p class="view"><a href="webdesign.html">Web Design<small>Some websites I designed</small></a></p>
        <p class="view"><a href="webdesign.html">About Me</a></p>
      </header>
      <section>
        <h2>Intelligent Search Engine based on Social Network Analysis</h2>
        <p><em>An innovation program affiliated with NJU IIP Group</em></p>
        <h3>Data Collection</h3>
        <p>Our experimental data collected from one of the major social networks - renren.com. The crawler used a multi-thread, API based solution, using MySQL for storage.</p>
        <h3>Search Framework</h3>
        <p>The index server is based on Lucene. We used a refined mechanism(see below) for word segmentation. The index process is synchronized with the crawling process.</p>
        <h3>Data Analysis</h3>
        <p>Two values were calculated:</p>
        <ul>
        <li>Similarity between user interests</li>
        <li>Intimacy between users</li>
        </ul>
        <p>The first value is estimated by the the Cosine Similarity of the words collection of the two users. The latter one is measured according to the interactions between users(eg. replies, visits).</p>
        <p>Based on the two values, we designed an algorithm to rank the search result generated by Lucene. The basic idea was to calculate a combined weight using content relevancy from Lucene and social relevancy from our algorithms for each result.</p>
        <p>We also performed community extraction within user's social network to see how well our algorithm works. In most cases, users from different groups(eg. junior school friends vs college friends) were well separated from each other.</p>
        <h3>Visualization</h3>
        <p>We used Gephi to do visualization on our social graph.</p>
        <h3>Some Corpus Mining Experiements</h3>
        <p>Since social network messages is naturally suitable for mining newly emerging net speaks, we want to take this advantage. We first did a enumerative word segmentation on all the messages we've got to get all possible words. Then we calculated three values: Frequency, Cohesion and Freedom for each word. The three values were used to filter out meaningless words combination. Finally the newly emerging net speaks were found and visualized.</p>
      </section>
      <footer>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>