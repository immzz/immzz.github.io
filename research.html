<!doctype html>
<html>
  <head>
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-54079632-1', 'auto');
  ga('send', 'pageview');

</script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Mingzhi Zeng, Master Candidate in Carnegie Mellon University</title>
    
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-54079632-1', 'auto');
  ga('send', 'pageview');

</script>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Mingzhi Zeng</h1>
        <p class="view"><a href="projects.html">Projects<small>Some codings and ideas</small></a></p>
        <p class="view"><a href="research.html">Research<small>Social Data Mining & Mechanism Design</small></a></p>
        <p class="view"><a href="other.html">Other<small>Games and Designs</small></a></p>
        <p class="view"><a href=".">About Me</a></p>
      </header>
      <section>
      	<h2>Click Auction Model based on Proportional-Share Allocation</h2>
        <p><em>Graduation thesis during study in Nanjing University. Part of the project Research on the Theory and Key Technology of Mechanism Design under Social Network Environment</em>.</p>
        <h3>Advisors</h3>
        <ul>
        <li>
        <p>Prof. Junyuan Xie</p>
        </li>
        <li>
        <p>Prof. Chongjun Wang</p>
        </li>
        </ul>
        <h3>Abstract</h3>
        <p>Search engines are turning into the ultimate form of retrieving and interacting with big and intelligent data. In the near future, online search will become the unified interface between human and massive information. Sponsored search, which is the fundamental way of profiting of search engines, is not flexible enough for advertisers since existing mechanisms sell slots with fixed expected clicks. Advertiser who has his unique budget and objective will want to get clicks tailored to his need. In this paper we introduce a new model named First-price Click Auction Model based on Proportional-Share Allocation (or First-price Click Auction Model for short). The FCA model introduced several algorithms to convert fixed slots into expected clicks, and an auction to allocate clicks proportionally according to bidders’ bids. We also present theoretical analysis on players’ best response, proof of the existence and uniqueness of Nash Equilibrium, and finally experiment result on real-world dataset from Yahoo! Labs. We discovered that, based on our experiment, the FCA model allocates better matched share of clicks to advertisers. Also, the FCA model has an overall performance in efficiency. Meanwhile, the new model’s platform revenue is slightly outperformed by the VCG mechanism.</p>
        <p><a href="docs/graduation_thesis_chinese.pdf">Original thesis in Chinese</a></p>
        
        <h2>Intelligent Search Engine based on Social Network Analysis</h2>
        <p><em>An innovation program affiliated with NJU IIP Group</em></p>
        <h3>Data Collection</h3>
        <p>Our experimental data collected from one of the major social networks - renren.com. The crawler used a multi-thread, API based solution, using MySQL for storage.</p>
        <h3>Search Framework</h3>
        <p>The index server is based on Lucene. We used a refined mechanism(see below) for word segmentation. The index process is synchronized with the crawling process.</p>
        <h3>Data Analysis</h3>
        <p>Two values were calculated:</p>
        <ul>
        <li>Similarity between user interests</li>
        <li>Intimacy between users</li>
        </ul>
        <p>The first value is estimated by the the Cosine Similarity of the words collection of the two users. The latter one is measured according to the interactions between users(eg. replies, visits).</p>
        <p>Based on the two values, we designed an algorithm to rank the search result generated by Lucene. The basic idea was to calculate a combined weight using content relevancy from Lucene and social relevancy from our algorithms for each result.</p>
        <p>We also performed community extraction within user's social network to see how well our algorithm works. In most cases, users from different groups(eg. junior school friends vs college friends) were well separated from each other.</p>
        <h3>Visualization</h3>
        <p>We used Gephi to do visualization on our social graph.</p>
        <h3>Some Corpus Mining Experiements</h3>
        <p>Since social network messages is naturally suitable for mining newly emerging net speaks, we want to take this advantage. We first did a enumerative word segmentation on all the messages we've got to get all possible words. Then we calculated three values: Frequency, Cohesion and Freedom for each word. The three values were used to filter out meaningless words combination. Finally the newly emerging net speaks were found and visualized.</p>
        <hr>
        
      </section>
      <footer>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>